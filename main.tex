\documentclass[format=acmsmall, review=false, screen=true]{acmart}

\usepackage{booktabs} % For formal tables

\usepackage[utf8]{inputenc}

% Metadata Information
\copyrightyear{2018}
%\acmArticleSeq{9}

% Copyright
%\setcopyright{acmcopyright}
\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}

% Paper history
\received{August 2018}

\newcommand \Elisp {Elisp}
\newcommand \MAlign [1] {\begin{array}{@{}l@{}}#1\end{array}}

% Document starts
\begin{document}
% Title portion. Note the short title for running heads
\title{Evolution of Emacs Lisp}

\author{Stefan Monnier}
\affiliation{%
  \institution{Université de Montréal}
  \streetaddress{C.P.\ 6128, succ.\ centre-ville}
  \city{Montréal}
  \state{QC}
  \postcode{H3C 3J7}
  \country{Canada}}
\email{monnier@iro.umontreal.ca}
\author{Michael Sperber}
\affiliation{%
  \institution{Active Group GmbH}
  \streetaddress{Hechinger Str.\ 12/1}
  \city{Tübingen}
  \country{Germany}
}
\email{sperber@deinprogramm.de}


\input abstract

\ccsdesc{Social and professional topics}
\ccsdesc{Professional topics}
\ccsdesc{History of computing}
\ccsdesc{History of programming languages}

%
% End generated code
%


\keywords{history of programming languages, Lisp, Emacs Lisp}


\maketitle

\section{Introduction}

\section{Prehistory}

%% Mocklisp, Maclisp, Scheme, TECO's language?

\section{Early history}         % -1992 ?

%% * Language & Implementation Overview
%% ** ... usual stuff ...
%% ** Buffer-local variables

%% ** Comparison to other Lisps of the time

%% ** Language implementation
%% ** Interpreter
%% ** Image dumping
%% ** Byte-code architecture (or should that go XEmacs-period?)

\section{XEmacs period}         % 1992-2007 ?

In 1991, Lucid Inc., a software development company based in Menlo
Park, Carlifornia, started a project called \textit{Energize}.
Energize was to be a C/C++ integrated development environment based on
Emacs~\cite{GabrielLetter}.  Lucid decided to use Emacs as the central
component of Energize.  At the time, the current version of Emacs was
18, which was still essentially a textual application.  The then
upcoming version of Emacs, Emacs 19, was to have a graphical user
interface and many other features that the developers at Lucid
considered essential for the development of Energize.  However, at the
time that Lucid needed Emacs 19, a release was not in
sight.\footnote{The first official release of Emacs 19, Emacs
  19.28, came out in on November 1, 1994.}

While Lucid at first tried to support and thus speed up the
development of Emacs 19, the required cooperation between Lucid and
the Free Software Foundation soon broke down.  As a result, Lucid
forked Emacs development, creating its own Emacs variant \textit{Lucid
Emacs}.\footnote{The first release of Lucid Emacs came out in April,
1992.}  Jamie Zawinski was the primary developer of Lucid Emacs.
In 1994, Lucid went bankrupt.  Sun subsequently wanted to ship
Lucid Emacs with their operating system, and ended up financing some
of the continued development of Lucid Emacs, and effected a name
change to the current \textit{XEmacs}.

The focus of Lucid Emacs was on providing a proper graphical user
interface.  As a result, most of the changes to Emacs Lisp in Lucid
Emacs / XEmacs were to support the move from a TTY-based purely
textual model to a graphical model.\foonote{Jamie Zawinski did write a new
  byte-compiler, but its focus was on speed and optimization, not on
  language features.}

\subsection{Event and keymap representations}


%  with richer character sets and
% richer input events

% keymap type


\subsection{Character representation}

% character type with XEmacs 20

%    Difference from Emacs 18:

% We have reimplemented keymaps so that sequences of events can be stored into
% them instead of just ASCII codes; it is possible to, for example, bind
% different commands to each of the chords Control-h, Control-H, Backspace,
% Control-Backspace, and Super-Shift-Backspace.  Key bindings, function key
% bindings, and mouse bindings live in the same keymaps.


% ** Major Differences Between 19.13 and 19.14
% ============================================

% -- Common-Lisp support (the CL package) is now dumped standard
%    into XEmacs.  No more need for (require 'cl) or anything
%    like that.

% ** Major Differences Between 19.6 and 19.8
% ==========================================

% There is a new internal representation for lisp objects, giving emacs-lisp 28
% bit integers and a 28 bit address space, up from the previous maximum of 26.
% We expect eventually to increase this to 30 bit integers and a 32 bit address
% space, eliminating the need for DATA_SEG_BITS on some architectures.  (On 64
% bit machines, add 32 to all of these numbers.)

\section{Emacs/XEmacs co-evolution}

\subsection{Bignums}

% bignums

% ** Major Differences Between 19.11 and 19.12
% ============================================


% *** Basic Lisp Stuff
% --------------------

% Common-Lisp backquote syntax is recognized.  For example, the old
% expression

% (` (a b (, c)))

% can now be written

% `(a b ,c)

% The old backquote syntax is still accepted.

% The new function `type-of' returns a symbol describing the type of a
% Lisp object (`integer', `string', `symbol', etc.)

% Symbols beginning with a colon (called "keywords") are treated
% specially in that they are automatically made self-evaluating when
% they are interned into `obarray'.  The new function `keywordp' returns
% whether a symbol begins with a colon.

% `get', `put', and `remprop' have been generalized to allow you to set
% and retrieve properties on many different kinds of objects: symbols,
% strings, faces, glyphs, and extents (for extents, however, this is not
% yet implemented).  They are joined by a new function `object-plist'
% that returns all of the properties that have been set on an object.

% New functions `plists-eq' and `plists-equal' are provided for
% comparing property lists (a property list is an alternating list
% of keys and values).

% The Common-Lisp functions `caar', `cadr', `cdar', `cddr', `caaar', etc.
% (up to four a's and/or d's), `first', `second', `third', etc. (up to
% `tenth'), `last', `rest', and `endp' have been added, for more
% convenient manipulation of lists.

% New function `mapvector' maps over a sequence and returns a vector
% of the results, analogous to `mapcar'.

% New functions `rassoc', `remassoc', `remassq', `remrassoc', and
% `remrassq' are provided for working with alists.

% New functions `defvaralias', `variable-alias' and `indirect-variable'
% are provided for creating variable aliases.

% Strings have a modified-tick that is bumped every time a string
% is modified in-place with `aset' or `fillarray'.  This is retrieved
% with the new function `string-modified-tick'.

% New macro `push' destructively adds an element to the beginning of a
% list.  New macro `pop' destructively removes and returns the first
% element of a list.



% * Lisp and internal changes in XEmacs 21.0
% ==========================================

% ** It is now possible to build XEmacs with support for 31-bit Lisp
% integers (normally, Lisp integers are only 28 bits wide on 32-bit
% machines.)  Configure with --use-minimal-tagbits to test.  With this
% change, the maximum buffer size on 32-bit machines is increased from
% 128M to 1G.  This setting will be made default in a future XEmacs
% version.


% * Lisp and internal changes in XEmacs 21.4
% ==========================================

% *** Instead of being lists of 256-character strings, case tables are
% now opaque objects.  The interface to access them is almost the same,
% except it now works for international characters, and you can set the
% case pairs using `put-case-table-pair'.  `set-case-table' and friends
% still support the old list/string based interface for backward
% compatibility.


%% How did XEmacs bootstrap?
%% Strings with text-properties?

\section{post-XEmacs}           % 2007-now ?

%% FIXME: I'm putting chunks of text here without knowing where they
%% should really go.

%% FIXME: This is somewhat revisionist in the sense that some of those
%% developments occurred before GNU and the FSF, so it's not clear exactly
%% if those designs were driven by a desire for Freedom, or by just more
%% mundane software-development good practices.
Emacs being the brain child of Richard Stallman, its design strives to
embody and showcase the ideals of Free Software.  For example, not only
should it be legal to get and modify the source code, but every effort
should be made to encourage the end-user to do so.  This has a profound
influence on the \Elisp{} language:
\begin{itemize}
\item The language should be accessible to a wide audience, so that as many
  people as possible can adapt Emacs to their own needs, without being
  dependent on the availability of someone with a technical expertise.
  This can be seen concretely in the inclusion in Emacs of the
  \emph{Introduction to Programming in Emacs Lisp}
  tutorial~\citep{ElispIntro} targeting users with no programming
  experience.  This has been a strong motivation to keep \Elisp{} on the
  minimalist side and to resist incorporation of many Common-Lisp features.
\item It should be easy for the end-user to find the relevant code in order
  to modify Emacs's behavior.   This has driven the development of elements
  such as the \emph{docstrings} and more generally the self-documenting
  aspect of the language.  It also imposes constraints on the evolution of
  the language: the use of some facilities, such as \emph{advice}, is
  discouraged because it makes the code more opaque.
\item Emacs should be easily portable to as many platforms as possible.
  This largely explains why \Elisp{} is still using a fairly naive
  mark\&sweep garbage collector, and why its main execution engine is
  a simple bytecode interpreter.
\end{itemize}

%% How to structure that?

%% ** Other implementations
%% *** Elisp in MIT Scheme
%%  Edwin, there's also a paper on this:
%%  https://archive.org/stream/bitsavers_mitaiaimAI_794650/AITR-1451_djvu.txt
%% In "down with emacs lisp" you also mention JEmacs.
%% *** Elisp in Guile
%% *** Elisp in Common-Lisp (Sam Steingold?)

%% * Language Evolution
%% ** Influence of Lisp Machine's editors like Zmacs?
%% ** CL
%% ** EIEIO/CLOS
%% ** lexical/static-scoping (and eager macroexpansion)
%% Mention Neubauer/Sperber ICFP 2011 paper
%% ** How 'bout evolution of typical programming style?
%% ** frame-local variables?
%% ** Evolution of the "core Elisp" language?
%% I'm thinking here of how when/unless/dolist/push/setf slowly migrated from
%% CL to subr.el in Emacs.
%% ** lack of tail-call elimination?
%% ** lack of modules?
%% ** what about tooling?
%% *** docstrings (and checkdoc)
%% *** Edebug
%% *** Advice?
%% *** the various `declare` thingies
%% indent, debug, doc-string, advertized-calling-convention, ...

\subsubsection{Lexical scoping}

While Scheme was already about to get its second revision when Richard
Stallman started to work on GNU Emacs, and Richard obviously knew about
Scheme, being developed in a nearby office, \Elisp{} was mostly derived from
Maclisp and used exclusively dynamic scoping.  The motivation for this
decision is not completely clear but seems to include:
\begin{itemize}
\item Familiarity: Richard was more familiar with Maclisp than Scheme, and
  lexical scoping was new whereas dynamic scoping was the
  tried-and-tested alternative.
\item Hackability: Scheme's lexical scoping makes it impossible to access
  variables in other scopes, so it provides a strong form of abstraction,
  which is great in many cases, but can be annoying to the end user who just
  wants to do a quick and dirty hack.  Similarly, Richard has often
  preferred to avoid the use of opaque datatypes, most famously for the
  representation of keymaps and characters.
\item Efficiency: It was perceived that closures would incur a cost that was
  not justified.  This was especially true in the context of the early Emacs
  which relied exclusively on interpretation to evaluate its \Elisp{} code.
\end{itemize}
Yet, very quickly, lexical scoping became the established standard in pretty
much all serious programming languages, including those of the Lisp family.
So of course, the question of adding lexical scoping to \Elisp{} has been
brought up many times.

The first implementation appeared quite early, in the form of the
\texttt{lexical-let} macro, which was part of the new \texttt{cl.el} by Dave
Gillespie \email{<daveg@synaptics.com>} introduced in 1993 and performed
a local form of closure-conversion.
While this macro was used in many packages, it was never considered as
a really good solution to the problem of providing lexical scoping.
The somewhat long name was likely a factor, but the reason was more probably
due to the fact that the code generated by the macro was less efficient than
equivalent dynamically-scoped code and was more difficult to debug because
the backtrace-based debugger showed you the gory details of the
macro-expansion rather than the corresponding source.  For these reasons,
\texttt{lexical-let} was only used in those particular cases where lexical
scoping was really beneficial.

Dynamic scoping had two main drawbacks in practice:
\begin{itemize}
\item The lack of closures.  Some packages circumvented the lack of closures
  by building lambda expressions on the fly with constructs like
  \texttt{`(lambda (x) (+ x ',y))}, which was quite tolerable, although it
  suffered from various problems such as the fact that macros within that
  closure were expanded late, and its code was not seen by the
  byte-compiler.  Emacs-23.1 introduced the curry operator
  \texttt{apply-partially} to cover similar use cases without
  those drawbacks.
\item The global visibility of variable names, requiring more care with the
  choice of local variable names.  The convention followed by Emacs to name
  all global variables with a package-specific prefix works well enough in
  most cases, but it was not sufficient for higher-order functions, like
  \texttt{reduce}, and it was also problematic in a few other cases such as
  the byte-compiler: in order to emit warnings about the use of undeclared
  variables, the byte-compiler just tested whether that variable was already
  known to Emacs, which always returned true for those variables locally
  bound by one of the functions on the call stack, such as the functions in
  the byte-compiler itself.  So some code was made uglier with long local
  variable names in order not to interfere with other local bindings, and
  these ``solutions'' were never complete.
\end{itemize}

The only fully satisfactory solution to the desire for lexical scoping in
\Elisp{} was that it should be the scoping used by default by all binding
constructs, as is the case in Common-Lisp.  But at the same time, there was
a non-negotiable need to preserve compatibility with existing \Elisp{} code,
although some limited breakage could be tolerated, of course.

The vast majority of existing \Elisp{} code was (and still is) agnostic to
the kind of scoping used in the sense that either dynamic or lexical scoping
gives the same result in almost all circumstances.  This was true of early
\Elisp{} code and has become even more true over time as the byte-compiler
started to warn about references to undeclared variables.  Warning about
unused variables would have probably pushed even more \Elisp{} code to be
agnostic.  But in any case, it seemed clear that despite the above, the
majority of Elisp packages relied somewhere on dynamic scoping.  So while
there was hope to be able to switch \Elisp{} to use lexical scoping, it was
not clear how to find the few places where dynamic scoping is needed so as
to avoid breaking too many existing packages.

In~\cite{Neubauer01}, the authors try to solve this problem by a code
analysis which instead of try to find the places where dynamic scoping is
needed, tries to find those bindings for which lexical scoping would not
change the resulting semantics.  This tool could have been used to
mechanically convert \Elisp{} packages to a lexically scoped version of
\Elisp{}, while preserving the semantics.  But that did not happen.
The reasons for that are unclear, but the lack of an existing lexically
scoped version of \Elisp{} to target was probably a big part of it, and
doubts over whether this approach was practical probably dissuaded other
people from implementing such a lexically scoped version of \Elisp{}.

Around 2002, Miles Bader started working on a branch of Emacs with support
for lexical scoping.  His approach to the problem was to bite the bullet and
have 2 languages: an \Elisp{} with dynamic scope and another with lexical
scope.  Each file was tagged to indicate which language was to be used, and
in turn, each function was tagged with which language it was using, so
functions using dynamic scope could seamlessly call functions with lexical
scope and vice versa.  This way, old code would keep working exactly as
before and any new code that wanted to benefit from lexical scoping would
simply have to add the corresponding ``\texttt{-*- lexical-binding:t -*-}''
at the beginning of the file.

The two languages were sufficiently similar that the new lexically scoped
variant only required minor changes to the existing interpreter.  But the
changes needed to support this new language in the byte-compiler were more
problematic, causing progress on this branch to be slow, probably also
because Miles was not very familiar with the corresponding
compilation techniques.  This branch was kept up-to-date with the main Emacs
development but the work was never completed.

It was only in 2010 that Stefan Monnier found a student (Igor Kuzmin)
interested in a summer project in which he tried to solve the problem
differently: instead of directly adding support for lexical scoping and
closures to the single-pass byte-compiler code (which required significant
changes to the code), the idea was to implement a separate pass to perform
closure conversion as a pre-processing step.  This freed the closure
conversion from the constraints imposed by the design of the single-pass
byte-compiler, making it much easier to implement, and it also significantly
reduced the amount of changes needed in the byte-compiler, thus reducing the
risk of introducing regressions.

And so 2 years later, Emacs-24.1 was released with support for lexical
scoping based on Miles Bader's \emph{lexbind} branch combined with Igor's
closure conversion.  The main focus at that point was to:
\begin{itemize}
\item minimize the changes to the existing code to limit incompatibility
  with existing \Elisp{} packages;
\item make sure performance of existing code was not affected by the
  new feature;
\item provide reliable support for the new lexical scoping mode, tho not
  necessarily with the best performance.
\end{itemize}

\subsubsection{Eager macro-expansion}


\subsubsection{Pcase}

While working on the lexical-binding feature, Stefan Monnier grew
increasingly frustrated at the shape of the code used to traverse the
abstract syntax tree, littered with \texttt{car}, \texttt{cdr} carrying too
little information, compared to the kind of code he'd write for that in
statically typed functional languages with algebraic datatypes.

So he started working on a pattern matching construct inspired by those
languages.  Before embarking on this project, he looked for existing
libraries providing this kind of functionality, finding many of them for
Common-Lisp and Scheme, but none of them satisfying his expectations: either
the generated code was not considered efficient enough, or the code seemed
too difficult to port to \Elisp{}, or the set of accepted patterns was too
limited and not easily extensible.

So the NIH syndrome struck again and the \texttt{pcase.el} package was born,
being first released as part of Emacs-24.1, and used extensively in the part
of the byte-compiler providing support for lexical-binding.

Additionally to the \texttt{pcase} macro itself which provides a superset of
Common-Lisp's \texttt{case} macro, this package also provides the
\texttt{pcase-let} macro which uses the same machinery and supports the same
patterns in order to deconstruct objects, but where it is allowed to assume
that the pattern does match and hence can skip all the tests, leaving only the
operations that extract data.

After the release of Emacs-24.1, Stefan was made aware of Racket's
\texttt{match} construct, which somehow eluded his earlier search for
existing pattern matching macros and whose design makes it easy to define
new patterns.  The implementation of Racket's \texttt{match} could not be
easily be reused in \Elisp{} because it relies too much on the compiler's
efficient handling of locally defined functions, but \texttt{pcase.el} was
improved to follow some of the design of Racket's \texttt{match}.
The new version appeared in Emacs-25.1 and the main novelty there was the
introduction of \texttt{pcase-defmacro} which can define new patterns
in a modular way, often using the new low-level pattern \texttt{app}.

\subsubsection{CL-lib}          %Released in Emacs-24.3

While the core of \Elisp{} has evolved very slowly over the years, the
evolution of other Lisps (mostly Scheme and Common-Lisp) has put pressure to
try and add various extensions to the language.  As it turns out, \Elisp{},
to a first approximation, can be seen as a subset of Common-Lisp, so already
in 1986 Cesar Quiroz wrote a \texttt{cl.el} package which provided various
Common-Lisp facilities implemented as macros.

Richard never wanted \Elisp{} to morph into Common-Lisp, but he saw the
value of offering such facilities, so this \texttt{cl.el} package was
included fairly early on into Emacs, and has been one of the most popular
packages, used by a large proportion of \Elisp{} packages.  Yet, Richard did
not want to impose \texttt{cl.el} onto any Emacs user, so he imposed
a policy where the use of \texttt{cl.el} was limited \emph{within} Emacs
itself.  More specifically, \Elisp{} packages bundled with Emacs were
restricted to limit their use of \texttt{cl.el} in such a way that
\texttt{cl.el} never needed to be loaded during a normal editing session.
Concretely, this meant that the only features of \texttt{cl.el} that could
be used were: macros and inlined functions.

The reasons why Richard did not want to use \texttt{cl.el} and turn \Elisp{}
into Common-Lisp are not completely clear, but the following elements seem
to have been part of the motivation:
\begin{itemize}
\item Common-Lisp was considered a very large language back then, so in all
  likelihood it would have taken a significant effort to really make
  \Elisp{} into a reasonably complete implementation of Common-Lisp.
\item Some aspects of Common-Lisp's design can incur an important efficiency
  cost, and Emacs already carried the stigma of \emph{eight megabytes and
    constantly swapping}, so there were good reasons to try and not make
  \Elisp{}'s efficiency any worse.
\item Keeping \Elisp{} small meant that users could participate in its
  development without having to learn all of Common-Lisp.  When inclusion of
  Common-Lisp features was discussed, Richard would often point the cost
  in terms of the need for more, and more complex, documentation.
\item The implementation of \texttt{cl.el} was fairly invasive, redefining
  some core \Elisp{} functions.
\item Finally, turning \Elisp{} into Common-Lisp would imply a loss of control,
  in that Emacs would be somewhat bound to Common-Lisp's evolution and would
  have to follow the decisions of the designers of Common-Lisp on most aspects.
\end{itemize}
Over the years, the importance of the first two points has waned to some
extent.  Also the popularity of the \texttt{cl.el} package, as well as the
relentless pressure from Emacs contributors asking for more Common-Lisp
features has also reduced the relevance of the third point.

%% FIXME: Describe how things have been integrated little by little over
%% the years.

During the development of Emacs-24.3 the issue of better integration of the
\texttt{cl.el} package came up again.  The main point of pressure was the
desire to use \texttt{cl.el} \emph{functions} within packages bundled with
Emacs.  The main resistance from Richard was coming from the last point
above, but this time, a compromise was found: replace
the \texttt{cl.el} package with a new package (called \texttt{cl-lib.el})
which provides the same facilities but with names which all use the
\texttt{cl-} prefix.  This way, the \texttt{cl-lib.el} package doesn't turn
\Elisp{} into the Common-Lisp language, but instead provides the Common-Lisp
facilities under its own namespace, leaving \Elisp{} free to evolve in its
own way.

%% FIXME: Mention how the 4th point was addressed by moving some things
%% (e.g. macroexpand-all) to Elisp (which was actually done already in 24.1
%% as part of the lexical-scoping work), and reimplementing others so
%% as to rely on less-invasive advice instead of blunt redefinition
%% (e.g. use a simple (tho hackish) `function` macro to implement `cl-labels`,
%% and advice `macroexpand` (rather than redefine it) for cl-symbol-macrolet).

\subsubsection{Generalized variables} %Released in Emacs-24.3

To facilitate the move to \texttt{cl-lib.el}, some frequently used
functionality from \texttt{cl.el} was moved directly to \Elisp{}.  The most
visible one is the support for \emph{generalized variables}, also variously
known as \emph{places}, \emph{generalized references}, or \emph{lvalues}.

But rather than take the existing \texttt{cl.el} code implementing the
support for \emph{setf} and friends, a fresh new implementation of the
concept was used.  The reasons for this new implementation were:
\begin{itemize}
\item NIH syndrome: the existing code was hard to follow.
\item The code made use of internal helper functions from \texttt{cl.el}
  which we wanted to keep in \texttt{cl.el}, so some significant massaging
  was needed anyway.
\item \texttt{cl.el} followed Common-Lisp's design, which the implementor of
  \emph{cl-lib} considered ugly.
\end{itemize}
In Common-Lisp, a \emph{place} is defined by providing a function which
turns it into a 5-tuple
\begin{displaymath}
  (\textsl{VARS}~\textsl{VALS}~\textsl{STORE-VAR}~\textsl{STORE-FORM}
  ~\textsl{ACCESS-FORM})
\end{displaymath}
such that for example \texttt{(push \textsl{EXP} \textsl{PLACE})} turns into:
\begin{displaymath}
  \MAlign{
    \texttt{(let ((v \textsl{EXP}))} \\
    \;\;\;\MAlign{
      \texttt{(let* (\textsl{VARS} = \textsl{VALS})} \\
      \;\;\;\MAlign{
        \texttt{(let ((\textsl{STORE-VAR} (cons v \textsl{ACCESS-FORM})))} \\
        \;\;\;\texttt{\textsl{STORE-FORM})))}}}}
\end{displaymath}
This imposes a fairly rigid structure which, while general enough to adapt
to most needs, can be burdensome and leads to verbose code with a lot
of plumbing, both in the implementation of places and in the implementation
of macros which take places as arguments.
%% For example, if we want to define a place
%% of the form $\texttt{(if~\textsl{TEST}~\textsl{PLACE1}~\textsl{PLACE2})}$
%% the above \texttt{push} will inevitably end up with one of two
%% possibilities:
%% \begin{itemize}
%% \item Check twice whether \textsl{TEST} was nil or not: once within
%%   \textsl{ACCESS-FORM} and once within \textsl{STORE-FORM}.
%% \item Do the check once within \textsl{VALS} to return a pair of an ``access
%%   function'' and a ``store function'' which are then called via
%%   \texttt{funcall} within \textsl{ACCESS-FORM} and \textsl{STORE-FORM}.
%% \end{itemize}

So the reimplementation uses a different design: a \emph{place} is defined
by turning it into a single higher-order function (instead of a 5-tuple).
This higher-order function takes as its sole argument a \textsl{DO} function
of 2 arguments, the \textsl{ACCESS-FORM} and the \textsl{STORE-FUNCTION}.
For example, the \texttt{push} macro could be naively implemented as:
\begin{verbatim}
    (defmacro push (EXP PLACE)
      `(let ((x ,EXP))
         ,(funcall (gv-get-place-function PLACE)
                   (lambda (ACCESS-FORM STORE-FUNCTION)
                     (funcall STORE-FUNCTION `(cons x ,ACCESS-FORM))))))
\end{verbatim}
tho instead, \Elisp{} provides a macro \texttt{gv-letplace} which lets us
write the above as:
\begin{verbatim}
    (defmacro push (EXP PLACE)
      `(let ((x ,EXP))
         ,(gv-letplace (ACCESS-FORM STORE-FUNCTION) PLACE
            (funcall STORE-FUNCTION `(cons x ,ACCESS-FORM)))))
\end{verbatim}
This design generally leads to cleaner and simpler code, and we can easily
provide backward compatibility wrappers for most of Common-Lisp's
primitives: any 5-tuple representation of a place can easily be turned into
a corresponding higher-order function.  The reverse is not true, however, so
this design precludes compatibility with \texttt{get-setf-method} (nowadays
called \texttt{get-setf-expansion}).

Breaking compatibility with \texttt{get-setf-expansion} was of course
a downside, but in practice this function was almost never used outside of
\texttt{cl.el} itself so very few packages were impacted by
this incompatibility.

%% %% FIXME: The above is already borderline for a *history* of Elisp, but
%% %% I think the examples below are past the line.
%% For reference here is the definition of the \texttt{nthcdr} place, in Emacs-23:
%% \begin{verbatim}
%% (define-setf-method nthcdr (n place)
%%   (let ((method (get-setf-method place cl-macro-environment))
%%         (n-temp (make-symbol "--cl-nthcdr-n--"))
%%         (store-temp (make-symbol "--cl-nthcdr-store--")))
%%     (list (cons n-temp (car method))
%%           (cons n (nth 1 method))
%%           (list store-temp)
%%           (list 'let (list (list (car (nth 2 method))
%%                                  (list 'cl-set-nthcdr n-temp (nth 4 method)
%%                                        store-temp)))
%%                 (nth 3 method) store-temp)
%%           (list 'nthcdr n-temp (nth 4 method)))))
%% \end{verbatim}
%% And here is the corresponding definition in Emacs-24:
%% \begin{verbatim}
%% (gv-define-expander nthcdr
%%   (lambda (do n place)
%%     (macroexp-let2 nil idx n
%%       (gv-letplace (getter setter) place
%%         (funcall do `(nthcdr ,idx ,getter)
%%                  (lambda (v) `(if (<= ,idx 0) ,(funcall setter v)
%%                            (setcdr (nthcdr (1- ,idx) ,getter) ,v))))))))
%% \end{verbatim}
%% While the intensive use of higher-order functions may be a bit of an
%% obstacle for some programmers, this code has much less plumbing, and it is
%% much easier to see that \texttt{n} and \texttt{place} are evaluated in the
%% proper order.

\subsubsection{Object-oriented programming} %Emacs-25.1

While \texttt{cl.el} early on (already in the version by Cesar Quiroz
%% FIXME: the new cl.el says "This package was written by Dave Gillespie;
%% it is a complete rewrite of Cesar Quiroz's original cl.el package of
%% December 1986.", but the RCS records only go back to 1991.
\email{<quiroz@cs.rochester.edu>}, which date back to 1986) provided
compatibility with Common-Lisp's \texttt{defstruct}, including the ability
to define new structs as extensions/subtypes of others, thus providing
a limited form of inheritance, actual support for object-oriented
programming in the form of method dispatch has been historically limited
in Emacs.

The first real step in that direction was the development of EIEIO by Eric
Ludlam around the end of 1995, beginning of 1996.  The name ``Enhanced
Implementation of Emacs Interpreted Objects'' hints at the earlier existence
%% FIXME: I asked Eric about it, waiting for his answer.
of some ``Emacs Interpreted Objects'' package but we were not able to find
any information about it.

EIEIO is an implementation of a subset of CLOS.  Its development was mostly
driven by actual needs of CEDET more than as an end in itself.  It included
support for most of CLOS's \texttt{defclass}, as well as support for
a subset of \texttt{defmethod}, more specifically it was limited to
single-dispatch methods, dispatching on the first argument, and it could
only dispatch based on types of \texttt{defclass} objects.  It also had
incomplete support for method combinations, only allowing \texttt{:before}
and \texttt{:after} methods but not \texttt{:around} nor any user-defined
additional qualifiers.

EIEIO spent most of its life as part of the CEDET package (a package
providing IDE-like features) before being integrated into Emacs-23.2 in
2010, along with most of CEDET.  Use of EIEIO within Emacs stayed fairly
limited, partly for reasons of inertia, but also because EIEIO suffered some
of the same problems as \texttt{cl.el} in that it was not
``namespace clean''.

At the end of 2014, Stefan Monnier started to try and clean up EIEIO so as
to be able to use it in more parts of Emacs.  The intention was basically to
add a ``\texttt{cl-}'' prefix as was done for \texttt{cl-lib} (because it
was perceived that an ``\texttt{eieio-}'' prefix would be too verbose to be
popular), but there was also a desire to improve the \texttt{defmethod} with
support for \texttt{:around} methods and dispatch on other types than those
defined with \texttt{defclass}.

But it became quickly evident that the implementation of method dispatch
needed a complete overhaul: rather than constructing combined methods
up-front and memoizing the result, as in typical CLOS implementations,
EIEIO's dispatch and \texttt{call-next-method} did all their work
dynamically, relying on dynamically-scoped variables to preserve state in
a way that was both brittle and somewhat inefficient.

So, instead of improving EIEIO's \texttt{defmethod}, a completely new
version of CLOS's \texttt{defmethod} was implemented in the new
\texttt{cl-generic.el} package, which appeared in Emacs-25.1.  The main
immediate downside was that the idea to cleanup the rest of EIEIO (which
implements \texttt{defclass} objects) ended up forgotten along the way.
The implementation is not super efficient, but it's already several times
faster than the previous one in EIEIO.  This package provides largely the
same featureset as CLOS's \texttt{defmethod}, except for some important
differences:
\begin{enumerate}
\item Method combinations cannot be specified per method like in CLOS, but
  instead new method combinations can be added globally by adding
  appropriate methods to \texttt{cl-generic-combine-methods}.  This seemed
  like a good idea, but there is no known user of this feature at this time,
  not even internal.
\item The set of supported specializers is not hard-coded.  Instead, they
  can be defined in a modular way via the notion of \emph{generalizer}
  inspired from~\cite{Rhodes14}.  This is used both internally (to define
  all the standard specializers) as well as in some external packages, most
  notably in EIEIO to support dispatching on \texttt{defclass} types.
\end{enumerate}
The main motivation for the first difference above was that CLOS's support
for method combinations seemed too complex: the cost of implementation was
not justified by the expected use of the feature, so it was replaced by
a much simpler mechanism.

As for the second difference, it was made necessary by the need to dispatch
on EIEIO objects even though \texttt{cl-generic.el} could not depend on
EIEIO since it was not clean enough.  There were other motivations for it,
tho: not only it was clearly desirable to be able to define new
specializers, but it also made the implementation of the main specializers
cleaner.

Just like in the CLOS MOP, there is a fair bit of delicate bootstrapping
involved: new specializers are defined by adding methods to the
\texttt{cl-generic-generalizers} generic function, so we first define the
\texttt{t} specializer in a somewhat ad-hoc way, of course, then we define
the \texttt{head} specializer (where $\texttt{(head \textsl{VAL})}$ means
that the method is only applicable if the argument's \texttt{car} is equal
to \textsl{VAL}), after which we use this new specializer to implement the
\texttt{eql} specializer.

While looking for existing code that could make use of this new machinery,
we found the need to support dispatching on contextual information
(i.e.~dispatching on the current state) rather than only on arguments.
So \texttt{cl-generic.el} also adds support to its \texttt{cl-defmethod} for
pseudo-arguments of the form ``\texttt{\&context (\textsl{EXP}
  \textsl{SPECIALIZER})}''.  This is used for methods which are only
applicable in specific contexts, such as in specific major modes or in
frames using a particular kind of GUI.

The implementation of \texttt{cl-generic.el} was accompanied by an extension
of the on-line help system so as to be able to give information not just
above \Elisp{} variables, functions, and faces but also other kinds of named
elements, starting with types.  And to go along with that the implementation
of \texttt{cl-defstruct} was improved to better preserve information about
the type hierarchy so that the on-line help system can be used to traverse
it.  This started as an attempt to adapt to \texttt{cl-generic.el} the EIEIO
facilities to explore interactively EIEIO objects and methods, but is more
modular and better integrated with the rest of Emacs's on-line help system.

\subsubsection{Actual objects}  %Emacs-26.1

While Emacs-25's \texttt{cl-generic.el} introduced object-oriented
programming facilities into \Elisp{}, objects (whether defined via
\texttt{cl-lib}'s \texttt{cl-defstruct} or EIEIO's \texttt{defclass}) were
still represented as vectors and hence couldn't be reliably distinguished
from vectors, for example to pretty-print them.

This was addressed in Emacs-26 by the introduction of the
\texttt{make-record} primitive and corresponding new object type.
Those \emph{records} are implemented just like the vectors used previously,
except that their tag indicates that they should be treated as records
instead of vectors, and that by convention the first field of a record is
supposed to contain a type descriptor, which can be just a \emph{symbol}.

The main complexity introduced by this change was the need for a new syntax
to print and read those new objects, as well as the incompatibility between
the printed representation of objects using the old vector-based encoding
and those using the new encoding.

\subsection{Implementation}



%% ** Bootstrap?
%% ** C FFI
%% ** JIT compiler attempts
%% ** Byte code changes
%% ** GC changes

\section{Conclusion}

%% * Future evolution
%% ** Multi-threading?
%% ** OCaml extensions?
%% ** Replacement by Scheme/Guile
%% ** Replacement by Common Lisp

\bibliographystyle{abbrvnat}
\bibliography{refs}

\end{document}
