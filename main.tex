\documentclass[format=acmsmall, review=false, screen=true]{acmart}

\usepackage{booktabs} % For formal tables

\usepackage[utf8]{inputenc}

% Metadata Information
\copyrightyear{2018}
%\acmArticleSeq{9}

% Copyright
%\setcopyright{acmcopyright}
\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}

% Paper history
\received{August 2018}

\newcommand \Elisp {Elisp}
\newcommand \MAlign [1] {\begin{array}{@{}l@{}}#1\end{array}}

% Document starts
\begin{document}
% Title portion. Note the short title for running heads
\title{Evolution of Emacs Lisp}

\author{Stefan Monnier}
\affiliation{%
  \institution{Université de Montréal}
  \streetaddress{C.P.\ 6128, succ.\ centre-ville}
  \city{Montréal}
  \state{QC}
  \postcode{H3C 3J7}
  \country{Canada}}
\email{monnier@iro.umontreal.ca}
\author{Michael Sperber}
\affiliation{%
  \institution{Active Group GmbH}
  \streetaddress{Hechinger Str.\ 12/1}
  \city{Tübingen}
  \country{Germany}
}
\email{sperber@deinprogramm.de}


\input abstract

\ccsdesc{Social and professional topics}
\ccsdesc{Professional topics}
\ccsdesc{History of computing}
\ccsdesc{History of programming languages}

%
% End generated code
%


\keywords{history of programming languages, Lisp, Emacs Lisp}


\maketitle

\section{Introduction}

\subsection{Organization of This Paper}

FIXME

\subsection{Emacs Lisp as a Succession of Software Projects}

FIXME

\section{Prehistory}

%% Mocklisp, Maclisp, Scheme, TECO's language?

While Emacs's original inception was as a set of macros for the TECO
editor, it had no high-level extensionsion language.  Arguably, the
strongest influences for Emacs Lisp were Gosling Emacs's Mock Lisp and
MacLisp.

\subsection{Gosling Emacs}

\textit{Unix Emacs}, written by James Gosling in
1980/1981~\cite{Gosling1981}, preserved in the history books
as \textit{Gosling Emacs}, was one of the immediate predecessors of
Emacs.  It featured an extension language called \textit{MLisp} or
\textit{Mock Lisp}, which bears visual resemblance to Emacs Lisp.
MLisp featured function definitions via \texttt{defun}, as well as
many built-in functions (such as \texttt{eolp},
\texttt{forward-character}, \texttt{save-excursion}) whose names
survive in Emacs Lisp.  Emacs contained some backwards-compatibility
support for MLisp until Emacs 21.2 in 2001.

MLisp was a quite limited language: It lacked cons cells and lists.
MLisp did have dynamic binding and local variables, but a peculiar
mechanism for passing arguments:  There were no named
parameters.  Instead, a program would invoke the \texttt{arg}
function: For example, \texttt{(arg 1)} would access the first
argument.  Moreover, argument expressions were essentially evaluated
in a call-by-name fashion by \texttt{arg}, and evaluation happened in
the dynamic environment of the callee.

\subsection{MacLisp}

Several other early incarnations of Emacs were written in Lisp,
notably on the Lisp Machine by Dan Weinreb and in
MacLisp~\cite{Moon1974} by Bernie Greenberg~\cite{Stallman2002}.  The
ensuing possibilities for extending the editor was attractive to
Richard Stallman, who wanted to write a new widely available version.
As a result, Emacs Lisp is a direct descendant of MacLisp.

\section{Early history}         % -1992 ?

Following Greenberg's Multics Emacs, Stallman decided to write a (for
him) second version of Emacs, which included \Elisp{} from the start.
As Greenberg's Emacs required a high-performance Lisp compiler to run
efficiently, Stallman decided to reimplement the basis for the new
Emacs in C, with an integrated Lisp interpreter.  Buffer manipulation
and redisplay were written in efficient C, higher-level functionality
in Lisp.

% Moved from abstract:

Many extension and configuration languages start out ``small,'' with
no ambition to grow into a full-fledged programming language.  TECO
and Gosling Emacs featured small languages that were too weak to
support the vision Richard Stallman had for Emacs.  Consequently,
Stallman took inspiration from MacLisp, and \Elisp{} started as a real
programming language with powerful abstraction facilities, thus
foregoing Greenspun's tenth rule.

%% FIXME: TODO
%% * Language & Implementation Overview
%% ** ... usual stuff ...
%% ** Buffer-local variables
%% ** Comparison to other Lisps of the time
%% ** Language implementation
%% ** Interpreter
%% ** Image dumping
%% ** Byte-code architecture (or should that go XEmacs-period?)

\subsection{Buffer-local variables}

FIXME

\subsection{Hooks}

FIXME

\section{XEmacs period}         % 1992-2007 ?

In 1991, Lucid Inc., a software development company based in Menlo
Park, Carlifornia, started a project called \textit{Energize}.
Energize was to be a C/C++ integrated development environment based on
Emacs~\cite{GabrielLetter}.  Lucid decided to use Emacs as the central
component of Energize.  At the time, the current version of Emacs was
18, which was still essentially a textual application.  The then
upcoming version of Emacs, Emacs 19, was to have a graphical user
interface and many other features that the developers at Lucid
considered essential for the development of Energize.  However, at the
time that Lucid needed Emacs 19, a release was not in
sight.\footnote{The first official release of Emacs 19, Emacs
  19.28, came out in on November 1, 1994.}

While Lucid at first tried to support and thus speed up the
development of Emacs 19, the required cooperation between Lucid and
the Free Software Foundation soon broke down.  As a result, Lucid
forked Emacs development, creating its own Emacs variant \textit{Lucid
Emacs}.\footnote{The first release of Lucid Emacs came out in April,
1992.}  Jamie Zawinski was the primary developer of Lucid Emacs.
In 1994, Lucid went bankrupt.  Sun subsequently wanted to ship
Lucid Emacs with their operating system, and ended up financing some
of the continued development of Lucid Emacs, and effected a name
change to the current \textit{XEmacs}.

The focus of Lucid Emacs was on providing a proper graphical user
interface.  As a result, most of the changes to Emacs Lisp in Lucid
Emacs / XEmacs were to support the move from a TTY-based purely
textual model to a graphical model.\footnote{Jamie Zawinski did write a new
  byte-compiler, but its focus was on speed and optimization, not on
  language features.}

\subsection{Event and keymap representations}

One significant departure from Emacs in Lucid Emacs was the
representation of keymaps: Emacs, to this day, uses a transparent
S-expression representation for keymaps.
%% FIXME: According to Git, Emacs supported sparse keymaps
%% (i.e. using an alist representation rather than a vector)
%% at least since May 6 1991 (there's no earlier record).
%% In terms of possible representation, this is not very different from
%% current Emacs, although the code is now a lot more featureful and
%% robust, especially w.r.t inheritance.
In Emacs 19, a keymap was
simply a two-element list whose car is the symbol \texttt{keymap} and
whose second element is a vector, indexed by character code.
%% FIXME: The May 6 1991 version of the code already used reorder_modifiers
%% to canonicalize events represented as symbols before looking them up, so
%% it worked pretty much the same as current Emacs.
%% So either XEmacs's keymaps date back to some earlier time than May 6 1991,
%% or they were motivated by something else (e.g. a general dislike
%% for the approach used in Emacs's src/keymap.c, or a feeling or knowledge that
%% making it handle extensions like (multiple) inheritance would be messy
%% (as the author of the multiple-inheritance support for Emacs, I can vouch
%% for it being quite messy/tricky).
This
representation did not gracefully extend to GUI-based input models,
which distinguish between, say, backspace and Control-H.\footnote{One
  problem with early Emacsen especially for early users was that
  %% FIXME: Quite so, but this only occurred under ttys, not under GUIs,
  %% because the issue was that the terminal did send C-h when the user
  %% hit Backspace, so it was not actually related to keymaps!
  Control-H would trigger help instead of deleting the character in
  front of the cursor.}

The current representation for keymaps is much richer---here is an
example~\cite{ELispManual2018}:
%
\begin{verbatim}
(keymap
 (3 keymap
    ;; C-c C-z
    (26 . run-lisp))
 (27 keymap
     ;; ‘C-M-x’, treated as ‘<ESC> C-x’
     (24 . lisp-send-defun))
 ;; This part is inherited from ‘lisp-mode-shared-map’.
 keymap
 ;; <DEL>
 (127 . backward-delete-char-untabify)
 (27 keymap
     ;; ‘C-M-q’, treated as ‘<ESC> C-q’
     (17 . indent-sexp)))
\end{verbatim}
%
This creates problems with software evolution: While Emacs offered
constructors and mutators for keymaps, Emacs code could, in principle,
just use the tools for manipulating S-expressions for creating
them---\texttt{cons}, \texttt{rplaca}, \texttt{rplacd} etc.  This code
would break in the face of the representation change, but would not
immediately trigger an error.

The developers Lucid Emacs of Lucid Emacs foresaw this problem, and
made keymaps into on opaque datatype, forbidding manipulation via the
S-expression primitives.  This allowed Lucid Emacs to evolve the
representations of keymaps to cater to a richer set of input events
(including mouse events, for instance), leaving existing Lisp programs
unaffected.

This step reflected a general difference in philosophy.  Lucid Emacs
also used opaque data types for case tables and input events, both of
which retain transparent representations in Emacs to this day.

\subsection{Character representation}

Another instance of a change in representation happened with the
release of XEmacs 20, the first release of XEmacs with support for
MULE (Multi-Lingual Emacs).

Previous versions of Emacs and XEmacs were inherently tied to an 8-bit
representation of characters.  Moreover, they had used strings not
only for representing text but also for representing key sequences.
In strings, the high bit represented ``meta,'' basically restricting
Emacs to ASCII.  Characters outside of strings could have more
modifiers in higher bits.

This situation was no longer tenable when multi-language support came
to XEmacs.  The work on MULE~\cite{Ohmaki2002} predates widespread
adoption of Unicode, and at the time XEmacs adopted MULE (around
1994), a number of other text encodings were still in use.  The MULE
character representation encoded a character as an integer that
represented two numbers, in the high and low bits respectively: One
represented the national character set, the other the associated
codepoint.

To enforce the separation between characters and their associated
encodings, XEmacs 20 made characters a separate data type.  XEmacs had
functions to convert between a character and its numerical
representation (\texttt{make-char} and \texttt{char-int}).  Generally,
Emacs Lisp allows programs to mostly handle text as strings,
and avoid manipulating the numerical representation.  Making
characters an opaque type additionally discouraged the practice.

% character type with XEmacs 20

%    Difference from Emacs 18:

% We have reimplemented keymaps so that sequences of events can be stored into
% them instead of just ASCII codes; it is possible to, for example, bind
% different commands to each of the chords Control-h, Control-H, Backspace,
% Control-Backspace, and Super-Shift-Backspace.  Key bindings, function key
% bindings, and mouse bindings live in the same keymaps.


% ** Differences between XEmacs and GNU Emacs 19
% ==================================================

%% FIXME: In Emacs-19, events were not only represented by integers but also
%% by symbols like `C-left` or `C-backspace`.  Not sure when they
%% were extended to also allows pairs of the form (NAME . DATA),
%% where NAME can be something like `C-mouse-1` and DATA gives extra
%% information such as the position of the click.
%%
% In XEmacs, events are first-class objects.  FSF 19 represents them as
% integers, which obscures the differences between a key gesture and the
% ancient ASCII code used to represent a particular overlapping subset of them.

% In XEmacs, keymaps are first-class opaque objects.  FSF 19 represents them as
% complicated combinations of association lists and vectors.  If you use the
% advertised functional interface to manipulation of keymaps, the same code
% will work in XEmacs, Emacs 18, and GNU Emacs 19; if your code depends
% on the underlying implementation of keymaps, it will not.


% ** Major Differences Between 19.13 and 19.14
% ============================================

% -- Common-Lisp support (the CL package) is now dumped standard
%    into XEmacs.  No more need for (require 'cl) or anything
%    like that.

% ** Major Differences Between 19.6 and 19.8
% ==========================================

% There is a new internal representation for lisp objects, giving emacs-lisp 28
% bit integers and a 28 bit address space, up from the previous maximum of 26.
% We expect eventually to increase this to 30 bit integers and a 32 bit address
% space, eliminating the need for DATA_SEG_BITS on some architectures.  (On 64
% bit machines, add 32 to all of these numbers.)

\section{Emacs/XEmacs co-evolution}

\subsection{Unicode}

%% FIXME: Emacs-21.1 already supported the `utf-8` coding-system, but it
%% was not unified with other charsets (just like the various iso-8859 charsets
%% weren't unified between themselves).  Emacs-22.1 introduced a form of
%% unification between the unicode charset and several other charsets.
%% This said, maybe we don't care about those details, who don't directly
%% affect the Elisp language (we should resist the temptation to talk about
%% Emacs rather than about Elisp).
%% IIUC XEmacs went through pretty much the same steps at around the same
%% time, although the implementation of the unification was quite
%% different, IIRC.
As Unicode~\cite{Unicode6} became universally adopted, Emacs
and XEmacs both supported the standard by converting between Unicode
and the internal MULE encoding.  This type of Unicode support appeared
in Emacs 22 and XEmacs 21.4 (both in 2001).

As Unicode evolved a universal text representation and supplanted many
of the earlier encodings,, Emacs and XEmacs both started efforts to
replace the internal MULE representation by Unicode altogether.  This
appeared in Emacs 23 (2007) and XEmacs 21.5 (starting about 2010 in a
separate branch).  As a result, the integer representation of a
character in both Emacs and XEmacs is its Unicode scalar value.

\subsection{Bignums}

%% FIXME: Mention the motivations for adding bignums (additionally to Calc),
%% i.e. those places where workarounds were used (e.g. using floats or lists
%% of integers for time and file sizes).
Somewhat surprisingly for Lisp, Emacs Lisp had no support for
arbitrarily large integers or \textit{bignums} for many years, despite
the fact that Emacs Lisp was used for more and more applications
beyond text editing.  As a result, Calc, an advanced calculator and
computer algebra tool, which has shipped with the Emacs distribution
%% FIXME: Maybe we should add details about how bignum support was added:
%% interaction with print&read, with `eql`, and with other primitives,
%% whether or not it was optional, ...
since 2001, had to implement bignum arithmetic in Lisp.  Jerry James
added bignums to XEmacs 21.5.18 in 2004.  Efforts to add bignums to
Emacs are underway at the time of writing of this article, in 2018.

% ** Major Differences Between 19.11 and 19.12
% ============================================


% *** Basic Lisp Stuff
% --------------------

% Common-Lisp backquote syntax is recognized.  For example, the old
% expression

% (` (a b (, c)))

% can now be written

% `(a b ,c)

% The old backquote syntax is still accepted.

% The new function `type-of' returns a symbol describing the type of a
% Lisp object (`integer', `string', `symbol', etc.)

% Symbols beginning with a colon (called "keywords") are treated
% specially in that they are automatically made self-evaluating when
% they are interned into `obarray'.  The new function `keywordp' returns
% whether a symbol begins with a colon.

% `get', `put', and `remprop' have been generalized to allow you to set
% and retrieve properties on many different kinds of objects: symbols,
% strings, faces, glyphs, and extents (for extents, however, this is not
% yet implemented).  They are joined by a new function `object-plist'
% that returns all of the properties that have been set on an object.

% New functions `plists-eq' and `plists-equal' are provided for
% comparing property lists (a property list is an alternating list
% of keys and values).

% The Common-Lisp functions `caar', `cadr', `cdar', `cddr', `caaar', etc.
% (up to four a's and/or d's), `first', `second', `third', etc. (up to
% `tenth'), `last', `rest', and `endp' have been added, for more
% convenient manipulation of lists.

% New function `mapvector' maps over a sequence and returns a vector
% of the results, analogous to `mapcar'.

% New functions `rassoc', `remassoc', `remassq', `remrassoc', and
% `remrassq' are provided for working with alists.

% New functions `defvaralias', `variable-alias' and `indirect-variable'
% are provided for creating variable aliases.

%% FIXME: Ha, didn't know about this one.  I'm eager to learn about the
%% motivation for this feature.
% Strings have a modified-tick that is bumped every time a string
% is modified in-place with `aset' or `fillarray'.  This is retrieved
% with the new function `string-modified-tick'.

% New macro `push' destructively adds an element to the beginning of a
% list.  New macro `pop' destructively removes and returns the first
% element of a list.



% * Lisp and internal changes in XEmacs 21.0
% ==========================================

% ** It is now possible to build XEmacs with support for 31-bit Lisp
% integers (normally, Lisp integers are only 28 bits wide on 32-bit
% machines.)  Configure with --use-minimal-tagbits to test.  With this
% change, the maximum buffer size on 32-bit machines is increased from
% 128M to 1G.  This setting will be made default in a future XEmacs
% version.


% * Lisp and internal changes in XEmacs 21.4
% ==========================================

% *** Instead of being lists of 256-character strings, case tables are
% now opaque objects.  The interface to access them is almost the same,
% except it now works for international characters, and you can set the
% case pairs using `put-case-table-pair'.  `set-case-table' and friends
% still support the old list/string based interface for backward
% compatibility.


%% How did XEmacs bootstrap?
%% Strings with text-properties?

\section{post-XEmacs}           % 2007-now ?

%% FIXME: I'm putting chunks of text here without knowing where they
%% should really go.

%% FIXME: This is somewhat revisionist in the sense that some of those
%% developments occurred before GNU and the FSF, so it's not clear exactly
%% if those designs were driven by a desire for Freedom, or by just more
%% mundane software-development good practices.
Emacs being the brain child of Richard Stallman, its design strives to
embody and showcase the ideals of Free Software.  For example, not only
is it legal to get and modify the source code, but every effort
is made to encourage the end-user to do so.  This has a profound
influence on the \Elisp{} language:
\begin{itemize}
\item The language should be accessible to a wide audience, so that as many
  people as possible can adapt Emacs to their own needs, without being
  dependent on the availability of someone with a technical expertise.
  This can be seen concretely in the inclusion in Emacs of the
  \emph{Introduction to Programming in Emacs Lisp}
  tutorial~\citep{ElispIntro} targeting users with no programming
  experience.  This has been a strong motivation to keep \Elisp{} on the
  minimalist side and to resist incorporation of many Common-Lisp features.
\item It should be easy for the end-user to find the relevant code in order
  to modify Emacs's behavior.  This has driven the development of elements
  such as the \emph{docstrings} and more generally the self-documenting
  aspect of the language.  It also imposes constraints on the evolution of
  the language: the use of some facilities, such as \emph{advice}, is
  discouraged because it makes the code more opaque.
\item Emacs should be easily portable to as many platforms as possible.
  This largely explains why \Elisp{} is still using a fairly naive
  mark\&sweep garbage collector, and why its main execution engine is
  a simple bytecode interpreter.
\end{itemize}

%% How to structure that?

%% FIXME:
%% ** Other implementations
%% *** Elisp in MIT Scheme
%%  Edwin, there's also a paper on this:
%%  https://archive.org/stream/bitsavers_mitaiaimAI_794650/AITR-1451_djvu.txt
%% In "down with emacs lisp" you also mention JEmacs.
%% *** Elisp in Guile
%% *** Elisp in Common-Lisp (Sam Steingold?)

%% FIXME:
%% * Language Evolution
%% ** old and new style backquotes
%% ** Influence of Lisp Machine's editors like Zmacs?
%% ** How 'bout evolution of typical programming style?
%% ** frame-local variables?
%% ** Evolution of the "core Elisp" language?
%% I'm thinking here of how when/unless/dolist/push/setf slowly migrated from
%% CL to subr.el in Emacs.
%% ** lack of tail-call elimination?
%% ** lack of modules?
%% ** what about tooling?
%% *** docstrings (and checkdoc)
%% *** Edebug
%% *** Advice?
%% *** the various `declare` thingies
%% indent, debug, doc-string, advertized-calling-convention, ...

\subsection{Lexical scoping}

While Scheme was already about to get its second revision when Richard
Stallman started to work on GNU Emacs, and Richard obviously knew about
Scheme, being developed in a nearby office, \Elisp{} was mostly derived from
Maclisp and used exclusively dynamic scoping.  The motivation for this
decision is not completely clear but seems to include:
\begin{itemize}
\item Familiarity: Richard Stallman was more familiar with Maclisp than Scheme, and
  lexical scoping was new whereas dynamic scoping was the
  tried-and-tested alternative.
\item Hackability: Scheme's lexical scoping makes it impossible to access
  variables in other scopes, so it provides a strong form of abstraction,
  which is great in many cases, but can be annoying to the end user who just
  wants to do a quick and dirty hack.
  % FIXME: evidence?
  Similarly, Richard Stallman has often
  preferred to avoid the use of opaque datatypes, most famously for the
  representation of keymaps and characters.
  % FIXME: Needs to tie in with XEmacs above
\item Efficiency: It was perceived that closures would incur a cost that was
  not justified.  This was especially true in the context of the early Emacs
  which relied exclusively on interpretation to evaluate its \Elisp{} code.
\end{itemize}
Yet, very quickly, lexical scoping became the established standard in
the Lisp family in both Common Lisp and Scheme.
So of course, the question of adding lexical scoping to \Elisp{} has been
brought up many times.

The first implementation appeared quite early, in the form of the
\texttt{lexical-let} macro, which was part of the new \texttt{cl.el} by Dave
Gillespie \email{<daveg@synaptics.com>} introduced in 1993 and performed
a local form of closure-conversion.
While this macro was used in many packages, it was never considered as
a really good solution to the problem of providing lexical scoping.
The somewhat long name was likely a factor, but the reason was more probably
due to the fact that the code generated by the macro was less efficient than
equivalent dynamically-scoped code and was more difficult to debug because
the backtrace-based debugger showed you the gory details of the
macro-expansion rather than the corresponding source.  For these reasons,
\texttt{lexical-let} was only used in those particular cases where lexical
scoping was really beneficial.

Dynamic scoping had two main drawbacks in practice:
\begin{itemize}
\item The lack of closures.  Some packages circumvented the lack of closures
  by building lambda expressions on the fly with constructs like
  \texttt{`(lambda (x) (+ x ',y))}, which suffered from various problems
  such as the fact that macros within that closure were expanded late, and
  its code was not seen by the byte-compiler.  Emacs-23.1 introduced the
  curry operator \texttt{apply-partially} to cover similar use cases without
  those drawbacks.
\item The global visibility of variable names, requiring more care with the
  choice of local names.  The convention followed in Emacs to name
  all global variables with a package-specific prefix works well enough in
  % FIXME: sufficient to do what?  Maybe code examples?
  most cases, but it was not sufficient for higher-order functions, like
  \texttt{reduce}, and it was also problematic in a few other cases such as
  the byte-compiler: in order to emit warnings about the use of undeclared
  variables, the byte-compiler just tested whether that variable was already
  known to Emacs, which always returned true for those variables locally
  bound by one of the functions on the call stack, such as the functions in
  the byte-compiler itself.  So some code was made uglier with long local
  variable names in order not to interfere with other local bindings, and
  these ``solutions'' were never complete.
\end{itemize}

The only fully satisfactory solution to the desire for lexical scoping in
\Elisp{} was that it should be the scoping used by default by all binding
constructs, as is the case in Common-Lisp.  But at the same time, there was
a non-negotiable need to preserve compatibility with existing \Elisp{} code,
although some limited breakage could be tolerated, of course.

The vast majority of existing \Elisp{} code was (and still is) agnostic to
the kind of scoping used in the sense that either dynamic or lexical scoping
gives the same result in almost all circumstances.  This was true of early
\Elisp{} code and has become even more true over time as the byte-compiler
started to warn about references to undeclared variables.  Warning about
unused variables would have probably pushed even more \Elisp{} code to be
agnostic.  But in any case, it seemed clear that despite the above, the
majority of Elisp packages relied somewhere on dynamic scoping.  So while
there was hope to be able to switch \Elisp{} to use lexical scoping, it was
not clear how to find the few places where dynamic scoping is needed so as
to avoid breaking too many existing packages.

In~\cite{Neubauer01}, the authors try to solve this problem by a code
analysis which, instead of trying to find the places where dynamic scoping is
needed, tries to find those bindings for which lexical scoping would not
change the resulting semantics.  This tool could have been used to
mechanically convert \Elisp{} packages to a lexically scoped version of
\Elisp{}, while preserving the semantics.  But that did not happen.
The reasons for that are unclear, but the lack of an existing lexically
scoped version of \Elisp{} to target was probably a big part of it, and
doubts over whether this approach was practical probably dissuaded other
people from implementing such a lexically scoped version of \Elisp{}.

Around 2002, Miles Bader started working on a branch of Emacs with support
for lexical scoping.  His approach to the problem was to bite the bullet and
have 2 languages: an \Elisp{} with dynamic scope and another with lexical
scope.  Each file was tagged to indicate which language was to be used, and
in turn, each function was tagged with which language it was using, so
functions using dynamic scope could seamlessly call functions with lexical
scope and vice versa.  This way, old code would keep working exactly as
before and any new code that wanted to benefit from lexical scoping would
simply have to add the corresponding ``\texttt{-*- lexical-binding:t -*-}''
at the beginning of the file.

The two languages were sufficiently similar that the new lexically scoped
variant only required minor changes to the existing interpreter.  But the
changes needed to support this new language in the byte-compiler were more
problematic, causing progress on this branch to be slow, probably also
because Miles was not very familiar with the corresponding
compilation techniques.  This branch was kept up-to-date with the main Emacs
development but the work was never completed.

It was only in 2010 that Stefan Monnier found a student (Igor Kuzmin)
interested in a summer project in which he tried to solve the problem
differently: instead of directly adding support for lexical scoping and
closures to the single-pass byte-compiler code (which required significant
changes to the code), the idea was to implement a separate pass to perform
closure conversion as a pre-processing step.  This freed the closure
conversion from the constraints imposed by the design of the single-pass
byte-compiler, making it much easier to implement, and it also significantly
reduced the amount of changes needed in the byte-compiler, thus reducing the
risk of introducing regressions.

And so 2 years later, Emacs-24.1 was released with support for lexical
scoping based on Miles Bader's \emph{lexbind} branch combined with Igor's
closure conversion.  The main focus at that point was to:
\begin{itemize}
\item minimize the changes to the existing code to limit incompatibility
  with existing \Elisp{} packages;
\item make sure performance of existing code was not affected by the
  new feature;
\item provide reliable support for the new lexical scoping mode, tho not
  necessarily with the best performance.
\end{itemize}

Performance of the new lexical scoping mode proved to be competitive
with the performance of the dynamic scoping mode except for its interaction
with the \texttt{condition-case} and \texttt{unwind-protect} primitives
whose underlying byte-codes were a poor fit.  So in Emacs-24.4, new byte
codes were introduced and the byte-compiler was modified to be able to make
use of them.

\subsection{Eager macro-expansion} %Emacs-24.3?

The exact time at which a macro is expanded has never been clearly specified
in \Elisp{}.  Until Emacs-24, macro-expansion usually took place as late as
possible for interpreted code, whereas for byte-compiled code,
macro-expansion always took place during byte-compilation, with some notable
exceptions where the code was ``hidden'' from the byte-compiler.  In the
byte-compiler, the macro-expansion was also done ``lazily'' in that it was
done on the fly during the single pass of compilation.

In order to implement the separate closure conversion phase for Emacs-24,
this had to be changed so that the code is macro-expanded in a separate
phase before closure conversion and the actual byte-compilation, using a new
\texttt{macroexpand-all} function.
This caused some visible differences in corner cases where some macros ended
up expanded in code which earlier was eliminated by optimizations before
getting to the point of macro-expansion, but in practice this did not cause
any serious regression.

This use of the new \texttt{macroexpand-all} function was made yet a bit
more prevalent in Emacs-24.3 where we started applying it when loading
a non-compiled file, so that macro-expansion now happens ``eagerly'' when
loading a file rather than lazily when we actually run the code.  This eager
macro-expansion occasionally bumped into problematic dependencies (typically
in files which were never compiled), so we made it fail gracefully: if an
error is signaled during the macro-expansion that takes place while loading
a file, we just abort the macro-expansion and continue with the non-expanded
code like we did in the past, tho not without duly notifying the user about
the problem.

In Emacs-25.1, we additionally fine-tuned these macro-expansion phases (both
while loading a file and while compiling them) according to the section
3.2.3.1 of the Common-Lisp HyperSpec~\cite{HyperSpec}, so as to improve the
handling of macros that expand to both definitions and uses of
those definitions.

\subsection{Pcase}           %Released in Emacs-24.1

While working on the lexical-binding feature, Stefan Monnier grew
increasingly frustrated at the shape of the code used to traverse the
abstract syntax tree, littered with \texttt{car}, \texttt{cdr} carrying too
little information, compared to the kind of code he'd write for that in
statically typed functional languages with algebraic datatypes.

So he started working on a pattern matching construct inspired by those
languages.  Before embarking on this project, he looked for existing
libraries providing this kind of functionality, finding many of them for
Common-Lisp and Scheme, but none of them satisfying his expectations: either
the generated code was not considered efficient enough, or the code seemed
too difficult to port to \Elisp{}, or the set of accepted patterns was too
limited and not easily extensible.

So the NIH syndrome struck again and the \texttt{pcase.el} package was born,
being first released as part of Emacs-24.1, and used extensively in the part
of the byte-compiler providing support for lexical-binding.

Additionally to the \texttt{pcase} macro itself which provides a superset of
Common-Lisp's \texttt{case} macro, this package also provides the
\texttt{pcase-let} macro which uses the same machinery and supports the same
patterns in order to deconstruct objects, but where it is allowed to assume
that the pattern does match and hence can skip all the tests, leaving only the
operations that extract data.

After the release of Emacs-24.1, Stefan was made aware of Racket's
\texttt{match} construct~\cite{RacketReference2018}, which somehow eluded
his earlier search for
existing pattern matching macros and whose design makes it easy to define
new patterns.  The implementation of Racket's \texttt{match} could not be
easily reused in \Elisp{} because it relies too much on the compiler's
efficient handling of locally defined functions, but \texttt{pcase.el} was
improved to follow some of the design of Racket's \texttt{match}.
The new version appeared in Emacs-25.1 and the main resulting novelty was the
introduction of \texttt{pcase-defmacro} which can define new patterns
in a modular way, often using the new low-level pattern \texttt{app}.

\subsection{Incorporating functionality from \texttt{cl.el}}

Over the years, various macros and functions from \texttt{cl.el} were found
to be sufficiently popular to move them into \Elisp{} proper:

\begin{itemize}
\item [Emacs-20.1]: The release of Emacs-20.1 saw the move of the macros
  \texttt{when} and \texttt{unless} as well as the functions \texttt{caar},
  \texttt{cadr}, \texttt{cdar}, and \texttt{cddr}.
\item [Emacs-21.1]: The hash-table functions, reimplemented in C, as well as
  the Common-Lisp concept of \emph{keywords} (tho only as objects, not as
  arguments).  Additionally the macros \texttt{dolist}, \texttt{dotimes},
  \texttt{push}, and \texttt{pop} were also added to \Elisp{}, which
  introduced some difficulties: in \texttt{cl.el} those macros included
  extra functionality which relied on parts of \texttt{cl.el} which we did
  not want to move to \Elisp{} proper, specifically
  \texttt{block}/\texttt{return} and generalized references.  For that
  reason those macros added! to \Elisp{} do not actually replace those of
  \texttt{cl.el}; instead when \texttt{cl.el} is loaded, it overrides the
  original macros with its own version.
\item [Emacs-22.1]: \texttt{delete-dups}, which provides a subset of
  \texttt{cl.el}'s \texttt{delete-duplicates}.
\item [Emacs-24.1]: \texttt{macroexpand-all} and lexical-scoping, which
  replaces \texttt{cl.el}'s \texttt{lexical-let}.
\item [Emacs-24.3]: Compiler macros, \texttt{setf} and
  generalized references.
\item [Emacs-26.1]: Additionally to the cXXr functions incorporated in
  Emacs-20.1, the cXXXr functions are now also part of \Elisp{}.
  The resistance against those was mostly one of style, since they tend to
  lead to poorly readable code.
\end{itemize}

\subsection{CL-lib}          %Released in Emacs-24.3

While the core of \Elisp{} has evolved very slowly over the years, the
evolution of other Lisps (mostly Scheme and Common-Lisp) has put pressure to
try and add various extensions to the language.  As it turns out, \Elisp{},
to a first approximation, can be seen as a subset of Common-Lisp, so already
in 1986 Cesar Quiroz wrote a \texttt{cl.el} package which provided various
Common-Lisp facilities implemented as macros.

Richard never wanted \Elisp{} to morph into Common-Lisp, but he saw the
value of offering such facilities, so this \texttt{cl.el} package was
included fairly early on into Emacs, and has been one of the most popular
packages, used by a large proportion of \Elisp{} packages.  Yet, Richard did
not want to impose \texttt{cl.el} onto any Emacs user, so he imposed
a policy where the use of \texttt{cl.el} was restricted \emph{within} Emacs
itself.  More specifically, \Elisp{} packages bundled with Emacs were
restricted to limit their use of \texttt{cl.el} in such a way that
\texttt{cl.el} never needed to be loaded during a normal editing session.
Concretely, this meant that the only features of \texttt{cl.el} that could
be used were: macros and inlined functions.

The reasons why Richard did not want to use \texttt{cl.el} and turn \Elisp{}
into Common-Lisp are not completely clear, but the following elements seem
to have been part of the motivation:
\begin{itemize}
\item Common-Lisp was considered a very large language back then, so in all
  likelihood it would have taken a significant effort to really make
  \Elisp{} into a reasonably complete implementation of Common-Lisp.
\item Some aspects of Common-Lisp's design can incur an important efficiency
  cost, and Emacs already carried the stigma of \emph{eight megabytes and
    constantly swapping}, so there were good reasons to try and not make
  \Elisp{}'s efficiency any worse.
\item Keeping \Elisp{} small meant that users could participate in its
  development without having to learn all of Common-Lisp.  When inclusion of
  Common-Lisp features was discussed, Richard would often point the cost
  in terms of the need for more, and more complex, documentation.
\item The implementation of \texttt{cl.el} was fairly invasive, redefining
  some core \Elisp{} functions.
\item Finally, turning \Elisp{} into Common-Lisp would imply a loss of control,
  in that Emacs would be somewhat bound to Common-Lisp's evolution and would
  have to follow the decisions of the designers of Common-Lisp on most aspects.
\end{itemize}
Over the years, the importance of the first two points has waned to some
extent.  Also the popularity of the \texttt{cl.el} package, as well as the
relentless pressure from Emacs contributors asking for more Common-Lisp
features has also reduced the relevance of the third point.

%% FIXME: Describe how things have been integrated little by little over
%% the years.

During the development of Emacs-24.3 the issue of better integration of the
\texttt{cl.el} package came up again.  The main point of pressure was the
desire to use \texttt{cl.el} \emph{functions} within packages bundled with
Emacs.  The main resistance from Richard was coming from the last point
above, but this time, a compromise was found: replace
the \texttt{cl.el} package with a new package (called \texttt{cl-lib.el})
which provides the same facilities but with names which all use the
\texttt{cl-} prefix.  This way, the \texttt{cl-lib.el} package doesn't turn
\Elisp{} into the Common-Lisp language, but instead provides Common-Lisp
facilities under its own namespace, leaving \Elisp{} free to evolve in its
own way.

%% FIXME: Mention how the 4th point was addressed by moving some things
%% (e.g. macroexpand-all) to Elisp (which was actually done already in 24.1
%% as part of the lexical-scoping work), and reimplementing others so
%% as to rely on less-invasive advice instead of blunt redefinition
%% (e.g. use a simple (tho hackish) `function` macro to implement `cl-labels`,
%% and advise `macroexpand` (rather than redefine it) for cl-symbol-macrolet).

\subsection{Generalized variables} %Released in Emacs-24.3

To facilitate the move to \texttt{cl-lib.el}, some frequently used
functionality from \texttt{cl.el} was moved directly to \Elisp{}.  The
most visible one is the support for \emph{generalized variables}, also
variously known as \emph{places}, \emph{generalized references}, or
\emph{lvalues}.  A generalized variable is a form that can be used as
an expression and an updateable reference.  The concept comes from
Common Lisp, and the Emacs implementation originally a part of
\texttt{cl.el}.  In both Common Lisp and Emacs, a number of special
forms take generalized variables as operands---in particular,
\texttt{setf}, which treats a generalized variable as a reference and
sets its value.

%% FIXME: reword a bit
In Common Lisp, macros accepting a place can ask \texttt{get-setf-expansion}
to turn it into a list of five elements:
% FIXME: I can't follow here. How is that function provided?
% Who calls it on what?
\begin{displaymath}
  (\textsl{VARS}~\textsl{VALS}~\textsl{STORE-VAR}~\textsl{STORE-FORM}
  ~\textsl{ACCESS-FORM})
\end{displaymath}
such that for example \texttt{(push \textsl{EXP} \textsl{PLACE})} turns into:
\begin{displaymath}
  \MAlign{
    \texttt{(let ((v \textsl{EXP}))} \\
    \;\;\;\MAlign{
      \texttt{(let* (\textsl{VARS} = \textsl{VALS})} \\
      \;\;\;\MAlign{
        \texttt{(let ((\textsl{STORE-VAR} (cons v \textsl{ACCESS-FORM})))} \\
        \;\;\;\texttt{\textsl{STORE-FORM})))}}}}
\end{displaymath}
This imposes a fairly rigid structure which, while general enough to adapt
to most needs, can be burdensome and leads to verbose code with a lot
of plumbing, both in the implementation of places and in the implementation
of macros which take places as arguments.

The original \texttt{cl.el} code followed this Common Lisp design.  But when
implementing the support for \emph{setf} and friends in \Elisp{}, a fresh
new implementation of the concept was used.  The reasons for this new
implementation were:
\begin{itemize}
\item NIH syndrome: the existing code was hard to follow.
\item The previous code made use of internal helper functions from
  \texttt{cl.el} which we wanted to keep in \texttt{cl.el}, so some
  significant massaging was needed anyway.
\item the implementor of \emph{cl-lib} considered this part of Common-Lisp's
  design ugly.
\end{itemize}
%% For example, if we want to define a place
%% of the form $\texttt{(if~\textsl{TEST}~\textsl{PLACE1}~\textsl{PLACE2})}$
%% the above \texttt{push} will inevitably end up with one of two
%% possibilities:
%% \begin{itemize}
%% \item Check twice whether \textsl{TEST} was nil or not: once within
%%   \textsl{ACCESS-FORM} and once within \textsl{STORE-FORM}.
%% \item Do the check once within \textsl{VALS} to return a pair of an ``access
%%   function'' and a ``store function'' which are then called via
%%   \texttt{funcall} within \textsl{ACCESS-FORM} and \textsl{STORE-FORM}.
%% \end{itemize}

So the reimplementation uses a different design: instead of a five element
list, a \emph{place} maps to a single higher-order function.
This higher-order function takes as its sole argument a \textsl{DO} function
of two arguments, the \textsl{ACCESS-FORM} and the \textsl{STORE-FUNCTION}.
For example, the \texttt{push} macro could be naively implemented as:
\begin{verbatim}
    (defmacro push (EXP PLACE)
      `(let ((x ,EXP))
         ,(funcall (gv-get-place-function PLACE)
                   (lambda (ACCESS-FORM STORE-FUNCTION)
                     (funcall STORE-FUNCTION `(cons x ,ACCESS-FORM))))))
\end{verbatim}
instead, \Elisp{} provides a macro \texttt{gv-letplace} which lets us
write the above as:
\begin{verbatim}
    (defmacro push (EXP PLACE)
      `(let ((x ,EXP))
         ,(gv-letplace (ACCESS-FORM STORE-FUNCTION) PLACE
            (funcall STORE-FUNCTION `(cons x ,ACCESS-FORM)))))
\end{verbatim}
This design generally leads to cleaner and simpler code, and we can easily
provide backward compatibility wrappers for most of Common-Lisp's
primitives.

Any 5-tuple representation of a place can easily be turned into
a corresponding higher-order function.  The reverse is not true, however, so
this design precludes compatibility with Common Lisp and
\texttt{cl.el}'s \texttt{get-setf-expansion}, which must produce the
five values described above.
Breaking compatibility with \texttt{get-setf-expansion}
% FIXME: What's get-setf-expansion?
was of course
a downside, but in practice this function was almost never used outside of
\texttt{cl.el} itself so very few packages were impacted by
this incompatibility.

%% %% FIXME: The above is already borderline for a *history* of Elisp, but
%% %% I think the examples below are past the line.
%% For reference here is the definition of the \texttt{nthcdr} place, in Emacs-23:
%% \begin{verbatim}
%% (define-setf-method nthcdr (n place)
%%   (let ((method (get-setf-method place cl-macro-environment))
%%         (n-temp (make-symbol "--cl-nthcdr-n--"))
%%         (store-temp (make-symbol "--cl-nthcdr-store--")))
%%     (list (cons n-temp (car method))
%%           (cons n (nth 1 method))
%%           (list store-temp)
%%           (list 'let (list (list (car (nth 2 method))
%%                                  (list 'cl-set-nthcdr n-temp (nth 4 method)
%%                                        store-temp)))
%%                 (nth 3 method) store-temp)
%%           (list 'nthcdr n-temp (nth 4 method)))))
%% \end{verbatim}
%% And here is the corresponding definition in Emacs-24:
%% \begin{verbatim}
%% (gv-define-expander nthcdr
%%   (lambda (do n place)
%%     (macroexp-let2 nil idx n
%%       (gv-letplace (getter setter) place
%%         (funcall do `(nthcdr ,idx ,getter)
%%                  (lambda (v) `(if (<= ,idx 0) ,(funcall setter v)
%%                            (setcdr (nthcdr (1- ,idx) ,getter) ,v))))))))
%% \end{verbatim}
%% While the intensive use of higher-order functions may be a bit of an
%% obstacle for some programmers, this code has much less plumbing, and it is
%% much easier to see that \texttt{n} and \texttt{place} are evaluated in the
%% proper order.

\subsection{Object-oriented programming} %Emacs-25.1

While \texttt{cl.el} early on (already in the version by Cesar Quiroz
%% FIXME: the new cl.el says "This package was written by Dave Gillespie;
%% it is a complete rewrite of Cesar Quiroz's original cl.el package of
%% December 1986.", but the RCS records only go back to 1991.
\email{<quiroz@cs.rochester.edu>}, which date back to 1986) provided
compatibility with Common-Lisp's \texttt{defstruct}, including the ability
to define new structs as extensions/subtypes of others, thus providing
a limited form of inheritance, actual support for object-oriented
programming in the form of method dispatch has been historically limited
in Emacs.

The first real step in that direction was the development of EIEIO by Eric
Ludlam around the end of 1995, beginning of 1996.  The official name ``Enhanced
Implementation of Emacs Interpreted Objects'' hints at the earlier existence
of some ``Emacs Interpreted Objects'' package but in reality the acronym
came before its expansion.  EIEIO started as an experiment to try use
an object system in Emacs, first following a model like that of C++, but
very soon switching to a CLOS-inspired model.

EIEIO is an implementation of a subset of CLOS.  Its development was mostly
driven by actual needs more than as an end in itself: the original
motivation was to try and play with an object request broker, then a widget
toolkit, and later switched to providing support for the CEDET package.
It included support for most of CLOS's \texttt{defclass}, as well as support
for a subset of \texttt{defmethod}, more specifically it was limited to
single-dispatch methods, dispatching on the first argument, and it could
only dispatch based on types of \texttt{defclass} objects.  It also had
incomplete support for method combinations, only allowing \texttt{:before}
and \texttt{:after} methods but not \texttt{:around} nor any user-defined
additional qualifiers.

EIEIO spent most of its life as part of the CEDET package (a package
providing IDE-like features) before being integrated into Emacs-23.2 in
2010, along with most of CEDET.  Use of EIEIO within Emacs stayed fairly
limited, partly for reasons of inertia, but also because EIEIO suffered some
of the same problems as \texttt{cl.el} in that it was not
``namespace clean''.

At the end of 2014, Stefan Monnier started to try and clean up EIEIO so as
to be able to use it in more parts of Emacs.  The intention was basically to
add a ``\texttt{cl-}'' prefix as was done for \texttt{cl-lib} (because it
was perceived that an ``\texttt{eieio-}'' prefix would be too verbose to be
popular), but there was also a desire to improve the \texttt{defmethod} with
support for \texttt{:around} methods and dispatch on other types than those
defined with \texttt{defclass}.

It became quickly evident that the implementation of method dispatch
needed a complete overhaul: rather than constructing combined methods
up-front and memoizing the result, as in typical CLOS implementations,
EIEIO's dispatch and \texttt{call-next-method} did all their work
dynamically, relying on dynamically-scoped variables to preserve state in
a way that was both brittle and somewhat inefficient.

So, instead of improving EIEIO's \texttt{defmethod}, a completely new
version of CLOS's \texttt{defmethod} was implemented in the new
\texttt{cl-generic.el} package, which appeared in Emacs-25.1.  The main
immediate downside was that the idea to cleanup the rest of EIEIO (which
implements \texttt{defclass} objects) ended up forgotten along the way.
The implementation is not super efficient, but it's already several times
faster than the previous one in EIEIO.  This package provides largely the
same featureset as CLOS's \texttt{defmethod}, except for some important
differences:
\begin{enumerate}
\item Method combinations cannot be specified per method like in CLOS, but
  instead new method combinations can be added globally by adding
  appropriate methods to \texttt{cl-generic-combine-methods}.  This seemed
  like a good idea, but there is no known user of this feature at this time,
  not even internal.
\item The set of supported specializers is not hard-coded.  Instead, they
  can be defined in a modular way via the notion of \emph{generalizer}
  inspired from~\cite{Rhodes14}.  This is used both internally (to define
  all the standard specializers) as well as in some external packages, most
  notably in EIEIO to support dispatching on \texttt{defclass} types.
\end{enumerate}
The main motivation for the first difference above was that CLOS's support
for method combinations seemed too complex: the cost of implementation was
not justified by the expected use of the feature, so it was replaced by
a much simpler mechanism.

As for the second difference, it was made necessary by the need to dispatch
on EIEIO objects even though \texttt{cl-generic.el} could not depend on
EIEIO since it was not clean enough.  There were additional motivations for
it, tho: not only it was clearly desirable to be able to define new
specializers, but it also made the implementation of the main specializers
cleaner, and most importantly it seemed like an interesting problem
to solve.

Just like in the CLOS MOP, there is a fair bit of delicate bootstrapping
involved: new specializers are defined by adding methods to the
\texttt{cl-generic-generalizers} generic function, so we first define the
\texttt{t} specializer in a somewhat ad-hoc way, of course, then we define
the \texttt{head} specializer (where $\texttt{(head \textsl{VAL})}$ means
that the method is only applicable if the argument's \texttt{car} is equal
to \textsl{VAL}), after which we use this new specializer to implement the
\texttt{eql} specializer.

While looking for existing code that could make use of this new machinery,
we found the need to support dispatching on contextual information
(i.e.~dispatching on the current state) rather than only on arguments.
So \texttt{cl-generic.el} also adds support to its \texttt{cl-defmethod} for
pseudo-arguments of the form ``\texttt{\&context (\textsl{EXP}
  \textsl{SPECIALIZER})}''.  This is used for methods which are only
applicable in specific contexts, such as in specific major modes or in
frames using a particular kind of GUI.

The implementation of \texttt{cl-generic.el} was accompanied by an extension
of the on-line help system so as to be able to give information not just
about \Elisp{} variables, functions, and faces but also other kinds of named
elements, starting with types.  And to go along with that, the implementation
of \texttt{cl-defstruct} was improved to better preserve information about
the type hierarchy so that the on-line help system can be used to traverse
it.  This started as an attempt to adapt to \texttt{cl-generic.el} the EIEIO
facilities to explore interactively EIEIO objects and methods, but is more
modular and better integrated with the rest of Emacs's on-line help system.

\subsection{Actual objects}  %Emacs-26.1

While Emacs-25's \texttt{cl-generic.el} introduced object-oriented
programming facilities into \Elisp{}, objects (whether defined via
\texttt{cl-lib}'s \texttt{cl-defstruct} or EIEIO's \texttt{defclass}) were
still represented as vectors and hence couldn't be reliably distinguished
from vectors, for example to pretty-print them.

This was addressed in Emacs-26 by the introduction of the
\texttt{make-record} primitive and corresponding new object type.
Those \emph{records} are implemented just like the vectors used previously,
except that their tag indicates that they should be treated as records
instead of vectors, and that by convention the first field of a record is
supposed to contain a type descriptor, which can be just a \emph{symbol}.

The main complexity introduced by this change was the need for a new syntax
to print and read those new objects, as well as the incompatibility between
the printed representation of objects using the old vector-based encoding
and those using the new encoding.

\subsection{Implementation}

%% FIXME: TODO
%% ** Byte-code interpreter optimisation
%% *** IIRC there was a round of micro-optimisation in the XEmacs interpreter
%% *** threaded implementation (using gcc's computed gotos)
%% ** Bootstrap?
%% ** C FFI
%% ** JIT compiler attempts
%% ** Byte code changes
%% ** GC changes

\subsection{Data representation and memory management}

Emacs started with a data representation of its boxed data based on 32bit
words.  Those used a 7bit tag located in the most significant bits, 1 extra
``mark'' bit (see below), and 24bit of immediate data: either an integer or
a pointer.  Not all the possible 128 tags were actually used, but the 24
remaining bits where amply sufficient to represent the needed pointers and
integers for the typical available memory of the machines of that time.

The memory management used a simple mark\&sweep garbage collection
algorithm, and allocated objects by blocs of 4KB dedicated to a particular
kind of objects: one bloc each for cons cells, floats, symbols, markers, and
strings, all other objects were allocated directly with \texttt{malloc}.
To avoid fragmentation in the blocs of strings, those were compacted during
each GC.  The ``mark'' bit in each 32bit box was not used for the object
contained in the 32bit box.  Instead it was used so that cons cells could
occupy only 2 words: the extra bit needed to store the mark\&sweep's
\emph{markbit} of each cons cell was stored in the ``mark'' bit of the first
word (i.e. of the \texttt{car}).

%% FIXME: Strings got text-properties some time between 19.1 and 19.7.

Over time, this tagging scheme became problematic, since it limited to 16 MB
the size of the Lisp heap and to 8MB the size of files that could be edited.
The limit on file size is fundamentally linked to the maximum representable
integer since that is how buffer positions are represented.

So in Emacs-19.29 the scheme was tweaked so that the tag was reduced to
3 bits, pushing the maximum file size to a more comfortable 128MB and the
maximum heap size to 256MB.  To reduce the tag to 3 bits, the less important
object types were placed into two groups: one group using the
\texttt{Lisp\_Misc} tag and another using the \texttt{Lisp\_Vector} tag.
The \texttt{Lisp\_Misc} tag was used for objects that could share the same
heap size as Lisp markers (6 words), and hence be allocated from the same
4KB bloc.  For some of those objects, it imposed a slight waste of space,
which was justified by the fact that objects using the \texttt{Lisp\_Vector}
tag had other extra costs: 2 words of header, plus the overhead of having
each object by allocated directly by \texttt{malloc}.

\subsubsection{Scanning the stack}
Until Emacs-21, the mark phase of the GC was precise: the global roots were
explicitly registered, the GC knew all the types of Lisp objects and where
were the fields that could contain references, and the roots from the stack
were also explicitly registered into a singly linked list itself directly
allocated on the stack.

The cost of properly registering/unregistering stack references was
perceived to be high: it slowed down execution, both directly by adding
administrative code and indirectly by preventing some variables from being
kept in registers, and it was a source of bugs, especially since some code
tried to be clever and avoid registering local references under the
assumption that the GC could not be triggered at that particular point.
Similarly, the relocation of strings was a frequent source of hard-to-track
bugs because only the references known to the GC were properly updated, so
the programmer had to be careful not to keep unboxed or unregistered
references to a string at any point where a GC was possible.

To try and address those concerns, for Emacs-21.1, Gerd
Moellman changed the string compaction code and implemented a conservative
stack scan.  Strings are split into the string object itself, of fixed size
and non-relocatable, and the relocatable string data to which the code
(almost) never keeps a direct reference.  In order to find out if a given
word found on the stack might be a potentially valid reference to a Lisp
object, it keeps a memory map that records which regions of the memory
contains which kinds of Lisp objects.  It could be used either in addition
to the singly linked list of registered references, as a kind of debugging
aide, or replace it altogether.

Thanks to the interactive nature of Emacs and its opportunistic GC strategy
which ensures that the GC is often run when the stack is almost empty, the
slower conservative stack scanning and the potential false positives it
introduces have not been a problem.  The maintenance of the memory map,
implemented as a red-black tree, was hence the main cost of this new stack
scanning, which proved competitive with the previous scheme.  The previous
scheme was kept in use on some rare systems until Emacs-25.1, where all the
register/unregister code of stack references could finally be removed.

\subsubsection{Squeezing the tag bits}
Of course, a limit of 256MB was not actually comfortable.  So during the
development of Emacs-22, the tagging scheme was reworked again.
First, the ``mark'' bit was removed, which doubled the previous limits.
Second the tag bits were moved to the least significant bits, allowing
the Lisp heap to grow as large as the full address space allowed.
To this end, the \emph{markbit} of cons cells was moved to a separate bitmap
stored alongside each bloc of cons cells, which required allocating those
blocs on 4KB alignment boundaries.  This avoided the use of one extra word
per cons cell, as was done previously for floats.  This same bitmap scheme
was of course also used for floats, thus reducing the typical heap size of
floats from 96 bits to 64 bits.  Reducing the heap size of floats to 64bits
and avoiding the use of 3 words for cons cells was not just motivated by
thriftiness but rather by the need to enforce that all objects be aligned on
a multiple of 8, so as to free the least significant 3 bits for use as
tag bits.

At that point, there was no illusion that a maximum file size of 256MB was
sufficient, but at the same time, the design of Emacs made it basically
impossible to view files larger than 4GB or edit files larger than 2GB (on
a 32bit system) anyway, no matter which tagging scheme we used, so there was
not a lot of room for improvement.

In Emacs-23.2 the tagging scheme was tweaked to use 2 tags for integers,
hence pushing the maximum file size to 512MB.

And to cover the remaining space, a new compilation option
\texttt{--with-wide-int} was introduced in Emacs-24.1 to make the boxed data
use 64bit on 32bit systems.  This imposes a significant extra cost in terms
of space and time but makes it possible to edit files up to about 2GB.
When this compilation option is used, tag bits are placed in the most
significant bits again, so that the 32bit of pointers can be extracted at no
cost at all.

In Emacs-24.3, the allocation of objects using the \texttt{Lisp\_Vector} tag
(which is used for many more object types than just vectors) was modified:
instead of calling \texttt{malloc} for each such objects, they are now
allocated from ``vector blocs''.  The motivation was not that
\texttt{malloc} was too slow, but that the implementation of our
conservative stack scanning keeps track of every part of the Lisp heap
allocated with \texttt{malloc} in a balanced tree, so every such
\texttt{malloc} costs us an $O(N \textsf{log} N)$ operation plus a heap
allocation of an extra tree node, which was very costly for small objects
both in time and space.

In Emacs-24.4, the representation of objects using the \texttt{Lisp\_Vector}
tag (which is used for many more object types than just vectors) was
improved so as to reduce their header from 2 words down to a single word.

In Emacs-27.1, the object representation was changed again: the distinction
between \texttt{Lisp\_Misc} and \texttt{Lisp\_Vector} was dropped by making
all objects use the \texttt{Lisp\_Vector} representation since it had been
improved sufficiently to be competitive with the special
\texttt{Lisp\_Misc} representation.

%% FIXME: With the addition of bignums in the upcoming Emacs-27, there's
%% a chance that this compilation option won't be needed any more!

\section{Alternative Implementations}

Implementation of Emacs Lisp have not been confined to Emacs and its
derivatives.  Two implementations---Edwin and JEmacs---are notable for
running Emacs Lisp code on editors implemented independently from
Emacs.  Moreover, Guile Scheme also comes with support for the Emacs
language.  These implementation all aim at running existing Emacs Lisp
code in alternative environments, and consequently feature no
significant language changes.

\subsection{Edwin}

Edwin is the editor that ships with MIT Scheme~\cite{MITScheme2014}.
Its user interface is based on that of Emacs.  Edwin is implemented
completely in Scheme, and Scheme is its native extension language.
Additionally, Matthew Birkholz implemented an \Elisp{} interpreter
in Scheme that was able to run substantial \Elisp{}
packages~\cite{Birkholz1993} at the time, among them the Gnus news reader.

\subsection{JEmacs}

JEmacs~\cite{Bothner2001} is an editor that ships with Kawa
Scheme~\cite{KawaScheme}.  JEmacs comes with support for running some
\Elisp{} code.  Its implementation (written partly in Java and
partly in Scheme) works by translating \Elisp{} code to Scheme, and
running the result.

\subsection{Guile}

Guile Scheme~\cite{Guile2018} was conceived as the universal extension
language of the GNU project, with the specific intention of replacing
Emacs Lisp at one point.  This has not happened (yet), but Guile does
ship with a partial implementation of \Elisp{} that translates
\Elisp{} programs to Guile's intermediate language.

\section{Conclusion}



%% FIXME: TODO
%% * Future evolution
%% ** Multi-threading?
%% ** OCaml extensions?
%% ** Replacement by Scheme/Guile
%% ** Replacement by Common Lisp

\bibliographystyle{abbrvnat}
\bibliography{refs}

\end{document}
